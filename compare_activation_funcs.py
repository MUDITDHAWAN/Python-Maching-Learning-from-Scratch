# -*- coding: utf-8 -*-
"""q2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1d8UlDXhR72XwodKmFMAxk8gN4Fb8WqW9
"""

# from google.colab import drive
# drive.mount('/content/drive')

# import os
# os.chdir("/content/drive/My Drive/ML-Sem5/ML_Assignment_3/")

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.utils import shuffle
import pickle
from sklearn.neural_network import MLPClassifier
from sklearn.manifold import TSNE
import seaborn as sns
from sklearn.preprocessing import StandardScaler

from Q1 import *

## Load MNIST Dataset 
df_train = pd.read_csv("mnist_train.csv")
df_test = pd.read_csv("mnist_test.csv")

## Shuffle and Create input arrays 
df_train = shuffle(df_train)
df_test = shuffle(df_test)
# df.reset_index()
y_train = df_train['label'].to_numpy()
df_train = df_train.drop(['label'], axis=1)
X_train = df_train.to_numpy() 

y_test = df_test['label'].to_numpy()
df_test = df_test.drop(['label'], axis=1)
X_test = df_test.to_numpy()

## Dict to specify model parameters
param_dict = {
    'n_layers': 5, 
    'layer_sizes': np.array([784, 256, 128, 64, 10]), 
    'activation': "relu", 
    'learning_rate': 0.1, 
    'weight_init': "normal", 
    'batch_size': 200, 
    'num_epochs': 100
}

highest_test_acc = 0
for activation_type in ["relu", "sigmoid", "linear", "tanh"]:
    print("\n Activation: ", activation_type)
    ## Specify the activation function for hidden layers
    param_dict['activation'] = activation_type

    ## Initialize the model 
    model = MyNeuralNetwork(param_dict['n_layers'], param_dict['layer_sizes'], param_dict['activation'], 
                param_dict['learning_rate'], param_dict['weight_init'], 
                param_dict['batch_size'], param_dict['num_epochs'])

    model = model.fit(X_train, y_train, validation_data=[X_test, y_test])
    file_name = "./Weights/"+activation_type + "_weights.pickle"
    model.save_weights(file_name)
    model_acc = model.score(X_test, y_test)

    ## Save weigths of the trained model
    if highest_test_acc < model_acc:
        model.save_weights("./Weights/best_acc.pickle")
        highest_test_acc = model_acc
    
    # break

## t-SNE visualization ofr best model 
model = MyNeuralNetwork(param_dict['n_layers'], param_dict['layer_sizes'], param_dict['activation'], 
                param_dict['learning_rate'], param_dict['weight_init'], 
                param_dict['batch_size'], param_dict['num_epochs'])

model.load_weights("./Weights/best_acc.pickle")

model.score(X_test, y_test)

## Fit t-SNE on the PCA transformed data 
X_embedded = TSNE(n_components=2).fit_transform(model.A_out[str(model.n_layers-2)].T)

## Plotting the t-SNE visualization 
plt.figure(figsize=(16,10))
sns.scatterplot(
    x=X_embedded[:,1], y=X_embedded[:,0],
    hue=y_test,
    palette=sns.color_palette(),
    legend="full",
    alpha=1
)
plt.title("t-SNE after PCA")
plt.savefig("./Plots/Q2_5.png")
plt.show()

## Dict to specify model parameters
param_dict = {
    'n_layers': 5, 
    'layer_sizes': np.array([784, 256, 128, 64, 10]), 
    'activation': "relu", 
    'learning_rate': 0.1, 
    'weight_init': "normal", 
    'batch_size': 256, 
    'num_epochs': 100
}

for activation_type in ["relu", "logistic", "identity", "tanh"]:
    print("\n Activation: ", activation_type)
    ## Specify the activation function for hidden layers
    param_dict['activation'] = activation_type

    clf = MLPClassifier(hidden_layer_sizes=param_dict['layer_sizes'][1:-1], activation=param_dict['activation'], solver='sgd', learning_rate='constant',  
                        alpha=0, batch_size=param_dict['batch_size'], shuffle=False, random_state=1, max_iter=100, 
                        learning_rate_init=param_dict['learning_rate']).fit(X_train, y_train)
    
    print("Accuracy score", clf.score(X_test, y_test))

