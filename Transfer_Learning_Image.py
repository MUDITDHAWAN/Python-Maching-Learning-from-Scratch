# -*- coding: utf-8 -*-
"""q4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1f0tV9PTLcPS-ESgyCUhvz2xwYv2hArS0
"""

# from google.colab import drive
# drive.mount('/content/drive')

# import os
# os.chdir("/content/drive/My Drive/ML-Sem5/ML_Assignment_3/")

import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset
import torch.nn.functional as F

import torchvision
from torchvision import models, transforms

import plotly.graph_objects as go
import matplotlib.pyplot as plt

import random
import time
import pickle

if torch.cuda.is_available():       
    device = torch.device("cuda")
    print(f'There are {torch.cuda.device_count()} GPU(s) available.')
    print('Device name:', torch.cuda.get_device_name(0))

else:
    print('No GPU available, using the CPU instead.')
    device = torch.device("cpu")

with open(r'./Data_Q4/train_CIFAR.pickle', "rb") as f:
     train_data = pickle.load(f)

with open(r"./Data_Q4/test_CIFAR.pickle", "rb") as f:
     test_data = pickle.load(f)

img_transforms = transforms.Compose([
        transforms.Resize(224),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                    std=[0.229, 0.224, 0.225])
    ])

class Dataset_Q4(Dataset):

    def __init__(self, data, imgs_transform):

        self.labels = data['Y']

        self.inp = data['X']

        self.image_transform = imgs_transform

    def __len__(self):
        return self.labels.shape[0]
    

    def __getitem__(self, idx):

        ip = torch.tensor(self.inp[idx,:], dtype=torch.float)
        ip = self.image_transform(ip.view(3, 32, 32))
        label = torch.tensor(self.labels[idx], dtype=torch.float).unsqueeze(0)

        return {'X': ip, 'y': label}

train_dataset = Dataset_Q4(train_data, img_transforms)

train_loader = DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)

test_dataset = Dataset_Q4(test_data, img_transforms)
test_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)

class Ques4(nn.Module):
    def __init__(self):
        super(Ques4, self).__init__()

        self.alex = models.alexnet(pretrained=True)
        for p in self.alex.parameters():
            p.requires_grad = False
            
        self.fc1 = nn.Linear(1000, 512)
        self.fc2 = nn.Linear(512, 256)
        self.fc3 = nn.Linear(256, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.alex(x)

        x = F.relu(self.fc1(x))

        x = F.relu(self.fc2(x))

        x = self.sigmoid(self.fc3(x))

        return x

model = Ques4()
model = model.to(device)

# Create the optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)

def train(model, loss_fn, optimizer, train_dataloader, val_dataloader=None, epochs=4, evaluation=False, device='cpu'):
    """Train the BertClassifier model.
    """
    # Start training loop
    costs = []   
    costs_test = [] 
    print("Training Loop \n")
    for epoch_i in range(epochs):
        ## Training 

        # Reset tracking variables at the beginning of each epoch
        total_loss, batch_loss, batch_counts = 0, 0, 0

        # Put the model into the training mode
        model.train()

        # For each batch of training data...
        for step, batch in enumerate(train_dataloader):

            X, y = batch["X"], batch["y"]

            X = X.to(device)
            y = y.to(device)

            # Zero out any previously calculated gradients
            model.zero_grad()

            # Perform a forward pass. This will return logits.
            logits = model(X)

            # Compute loss and accumulate the loss values
            loss = loss_fn(logits, y)

            total_loss += loss.item()

            # Perform a backward pass to calculate gradients
            loss.backward()

            # Clip the norm of the gradients to 1.0 to prevent "exploding gradients"
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)

            # Update parameters and the learning rate
            optimizer.step()

        # Calculate the average loss over the entire training data
        avg_train_loss = total_loss / len(train_dataloader)
        costs.append(avg_train_loss)
        if ((epoch_i+1) % 10) == 0 :
            print("Epoch : {} | Training Loss : {}".format(epoch_i+1, avg_train_loss))
        # Evaluation
        if evaluation == True:
            # After an epoch - validation 
            val_loss, val_accuracy = evaluate(model, loss_fn, val_dataloader)     
            if ((epoch_i+1) % 10) == 0 :       
                print("Epoch : {} | Validation Loss : {} , Validation Accuracy : {}".format(epoch_i+1, val_loss, val_accuracy))

            costs_test.append(val_loss)
    print("Training complete!")

    # plot the cost
    plt.plot(costs, label="Training Loss")
    plt.plot(costs_test, label="Validation Loss")
    plt.ylabel('cost')
    plt.xlabel('epoch')
    plt.legend()
    # plt.title(""))
    plt.show()

    return avg_train_loss, val_loss, val_accuracy
    
    
    
def evaluate(model, loss_fn, val_dataloader):
    ## put the model in evaluation mode 
    model.eval()

    # Tracking variables
    val_accuracy = []
    val_loss = []

    # For each batch in our validation set...
    for batch in val_dataloader:
        X, y = batch["X"], batch["y"]

        X = X.to(device)
        y = y.to(device)
        # Compute logits
        with torch.no_grad():
            logits = model(X)

        # Compute loss
        loss = loss_fn(logits, y)

        val_loss.append(loss.item())

        # Get the predictions
        # preds = torch.argmax(logits, dim=1).flatten()
        preds = logits>0.5

        # Calculate the accuracy rate
        accuracy = (preds == y).cpu().numpy().mean() * 100
        val_accuracy.append(accuracy)

    # Compute the average accuracy and loss over the validation set.
    val_loss = np.mean(val_loss)
    val_accuracy = np.mean(val_accuracy)

    return val_loss, val_accuracy

train(model, nn.BCELoss(), optimizer, train_loader, test_loader, 10, True, device=device)

torch.save(model.state_dict(), "trained_model_q_4.pt")

y_score = []
y_pred = []
y_true = []
for step, batch in enumerate(test_loader):
    X, y = batch["X"], batch["y"]

    X = X.to(device)
    y = y.to(device)
    # Compute logits
    with torch.no_grad():
        logits = model(X)

    preds = logits>0.5

    # print(logits.shape)    
    # print(preds.shape)
    y_score.append(logits.squeeze().cpu().numpy())
    
    y_pred.append(preds.squeeze().cpu().numpy())

    c = (preds == y).squeeze().cpu().numpy()
    y_true.append(y.squeeze().cpu().numpy())

from sklearn.metrics import *

y_true_new = np.concatenate(y_true, axis=0)
y_score_new = np.concatenate(y_score, axis=0)
y_pred_new = np.concatenate(y_pred, axis=0)

tn, fp, fn, tp = confusion_matrix(y_true_new, y_pred_new).ravel()
print("TN: {} | FP: {} | FN: {} | TP: {} ".format(tn, fp, fn, tp))

fpr, tpr, _ = roc_curve(y_true_new, y_score_new)
roc_auc = auc(fpr, tpr)


plt.plot(fpr, tpr, color='darkorange', label='ROC curve area = '+str(roc_auc))
plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('FPR')
plt.ylabel('TPR')
plt.title('Receiver operating characteristic ')
plt.legend(loc="lower right")
plt.savefig("./Plots/Q4_ROC.png")
plt.show()

print("Accuracy : " , str(accuracy_score(y_true_new, y_pred_new)))

nb_imgs = 9

images = [torch.tensor(train_data['X'][i], dtype=torch.int32) for i in range(nb_imgs)] 

rows = int(np.sqrt(nb_imgs))
cols = int(np.sqrt(nb_imgs))

fig = plt.figure()
for i in range(rows*cols):
    ax = fig.add_subplot(rows, cols, i+1)
    ax.imshow(images[i].view((3, 32, 32)).permute(1, 2, 0).numpy())
    ax.axis('off')

print(np.unique(train_data['Y'], return_counts=True))
print("Number of samples with label 1 : {}, Number of samples with label 0 : {}".format(np.count_nonzero(train_data['Y']), len(train_data['Y']) -np.count_nonzero(train_data['Y'])))

