# -*- coding: utf-8 -*-
"""ques3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14iNT2s92lJe0CTGswiwoyHSDFJSP36m2
"""

# from google.colab import drive
# drive.mount('/content/drive')

import os
# os.chdir("/content/drive/My Drive/ML-Sem5/ML_Assignment-2/Dataset/")
os.chdir("./Dataset/")
import pandas as pd
import h5py
import numpy as np
import tqdm
import matplotlib.pyplot as plt
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
import plotly.graph_objects as go
from sklearn.tree import DecisionTreeClassifier
import pickle

def read_data(file_name):
    A_data = h5py.File(file_name, 'r')
    X = A_data['X'].value
    Y = A_data['Y'].value
    
    return X, Y

def create_k_folds(X, y, k):
  """
    Create k-folds for the given data set

    Parameters
    ----------
    X : 2-dimensional numpy array of shape (n_samples, n_features) which acts as testing data.

    y : 1-dimensional numpy array of shape (n_samples,) which contains the predicted values.

    k : number of folds.

    Returns
    -------
    Generator : FOlds of the given data  
    """
  ## X - (n_samples, n_features)

  nb_samples = X.shape[0]
  
  ## Split data into 'k' folds - folds have nb_samples//k samples atleast 
  fold_sizes = [nb_samples//k] *k

  ## Samples left after distributing others equally in k folds 
  extra = nb_samples % k

  ## first "extra" folds would have (nb_samples//k +1) samples
  fold_sizes = [fold_sizes[idx]+1 if (idx<extra) else fold_sizes[idx] for idx in range(k) ] 
  
  
  start_idx =0

  for fold_idx, curr_size in enumerate(fold_sizes):
    # print("Fold Index: {}, Fold Size: {}".format(str(fold_idx+1), str(curr_size)))

    ## index for the end of one fold 
    end_idx = start_idx + curr_size

    ## returning a generator
    yield fold_idx, X[start_idx: end_idx,:], y[start_idx: end_idx]

    start_idx = end_idx # assigning end index to start index for the next fold

def k_fold_cross_validation(model, X, y, k, max_depth=None):
    """
    Perform k-fold Cross-Validation for the given data set

    Parameters
    ----------
    X : 2-dimensional numpy array of shape (n_samples, n_features) which acts as testing data.

    y : 1-dimensional numpy array of shape (n_samples,) which contains the predicted values.

    k : number of folds.

    Returns
    -------

    """

    ## store validation loss for each fold 
    fold_acc_validation = []
    fold_acc_train = []

    ## Perform experiment "k" times 
    for idx_test in range(k):

        ## create zero arrays to which data for each fold will be separated and concatenated into train and test 
        # To be deleted later (just used for concatenation)
        X_train = np.zeros((1,X.shape[1]))
        X_test = np.zeros((1,X.shape[1]))
        y_train = np.zeros((1,))
        y_test = np.zeros((1,))

        ## Test Fold 
        print(" Fold for Validation - {}".format((str(idx_test+1))))

        ## Loop over the different folds to create Train and Test data for the given fold 
        for idx, x_fold, y_fold in create_k_folds(X,y,k):
            # print(x_fold.shape)
            ## Sepate Train from Test
            if idx == idx_test :
                X_test = np.concatenate([X_test, x_fold], axis=0)
                y_test = np.concatenate([y_test, y_fold], axis=0)
            else:
                X_train = np.concatenate([X_train, x_fold], axis=0)
                y_train = np.concatenate([y_train, y_fold], axis=0)
        
        ## Delete first zero-row which was added just for concatenation
        X_train = np.delete(X_train, (0), axis=0)
        X_test = np.delete(X_test, (0), axis=0)
        y_train = np.delete(y_train, (0), axis=0)
        y_test = np.delete(y_test, (0), axis=0)

        ## Initiallize the DT
        if max_depth==None:
            model_instance = model()
        else:
            model_instance = model(max_depth=max_depth)

        ## Fit the model for the fold 
        model_instance.fit(X_train, y_train)

        ## Evaluate on Train set
        train_acc_fold = model_instance.score(X_train, y_train)
        print("Training Acc :", train_acc_fold)
        fold_acc_train.append(train_acc_fold)

        ## Evaluate on Test set
        val_acc_fold = model_instance.score(X_test, y_test)
        print("Validation Acc : ", val_acc_fold)
        fold_acc_validation.append(val_acc_fold)
    
    #   estimate_var = 0 
    avg_train_acc = sum(fold_acc_train)/k
    avg_val_acc = sum(fold_acc_validation)/k
    print("Avg Training Acc - ", avg_train_acc)
    print("Avg Validation Acc - ", avg_val_acc)
    print("##########################################################################################")

    return model_instance, avg_train_acc, avg_val_acc

class GridSearch():
    """
    My implentation of Grid Search

    """
    def __init__(self, model, parameters):

        self.model = model
        self.parameters = parameters
        self.best_model = None
        self.max_acc = 0
        self.performance_dict_train = {}
        self.performance_dict_val = {}

    def fit(self, X, y, k):  
        """
        Trains and validates model for all the specified parameters using k-fold 
        cross validation

        Parameters
        ----------
        X : 2-dimensional numpy array of shape (n_samples, n_features) which acts as testing data.

        y : 1-dimensional numpy array of shape (n_samples,) which contains the predicted values.

        k : number of folds.

        """

        ## Loop over the valuse for the specified parameter 
        for max_len in self.parameters["max_depth"]:
            print("Max Depth : ", max_len)

            ## use k-fold cross validation to train and test the model for the given parameter 
            model, mean_acc_train, mean_acc_val = k_fold_cross_validation(self.model, X,y,k, max_len)

            ## save the performace of the model for the parameter value 
            self.performance_dict_train[max_len] = mean_acc_train
            self.performance_dict_val[max_len] = mean_acc_val

            ## check for the best model and save it as a class attribute 
            if mean_acc_val > self.max_acc :
                print("Best model change")
                self.best_model = model
                self.max_acc = mean_acc_val
    
    def save_best_model(self, file_name):
        """
        Saves the best model on disk 
        """
        pickle.dump(self.best_model, open(file_name, 'wb'))

    def load_saved_model(self, file_name):
        """
        Loads the best model from the disk 
        """
        self.best_model = pickle.load(open(file_name, 'rb'))

    def plot_acc_vs_param(self):
        """
        Plots the average training and validation accuracies for different parameter values 
        """

        ## create a plotly figure for the performance values 
        fig = go.Figure(data=[
            go.Bar(name='Training Accuracy', x=list(self.performance_dict_train.keys()), y=list(self.performance_dict_train.values())),
            go.Bar(name='Validation Accuracy', x=list(self.performance_dict_val.keys()), y=list(self.performance_dict_val.values()))
        ])

        ## plot train and validation accuracies for one value together 
        fig.update_layout(barmode='group')
        fig.show()

def eval_model(y_true, y_pred, labels):
    """
    Evaluates the model's predictions (Classification)

    Parameters
    ----------
    y_true : 1-dimensional numpy array of shape (n_samples,) which contains the true values.

    y_pred : 1-dimensional numpy array of shape (n_samples,) which contains the predicted values.

    labels : list of output classes.

    Returns 
    -------

    eval_metrics, macro_avg, micro_avg : corresponding values for multi-label classification case

    tp, fp, tn, fn : corresponding values for binary classification case 

    """

    ## For multi-label classification case 
    if(len(labels)> 2):

        ## store class-wise metrics 
        eval_metrics = {}

        micro_tp = 0

        ## loop over all the labels 
        for label in labels:
            print(label)

            ## calculate the label-wise true positive value
            micro_tp += np.sum(np.logical_and(y_pred==y_true, y_true==label)).astype(int)

            ## calculate the label-wise Precision value
            pr = np.sum(np.logical_and(y_pred==y_true, y_true==label)).astype(int) / np.sum(y_pred==label).astype(int)

            ## calculate the label-wise Recall value
            rec = np.sum(np.logical_and(y_pred==y_true, y_true==label)).astype(int) / np.sum(y_true==label).astype(int)

            ## calculate the label-wise F1-score value
            f1_score = 2*pr*rec / (pr + rec)

            ## add to the final dictionary 
            eval_metrics[label] = {'precision': pr , 'recall': rec, 'F1-score': f1_score}
        
        ## calculate the macro-average value 
        macro_avg = {}
        for metric in ['precision', 'recall', 'F1-score']:
            macro_avg[metric] = sum([eval_metrics[label][metric] for label in labels])/ len(labels)

        ## calculating average 
        micro_avg = micro_tp / y_true.shape[0]

        return eval_metrics, macro_avg, micro_avg
    else: 
        ## calculate the true positive value
        tp = np.sum(np.logical_and(y_pred==y_true, y_true==1)).astype(int)
        # print(tp)

        ## calculate the true negative value
        tn = np.sum(np.logical_and(y_pred==y_true, y_true==0)).astype(int)
        # print(tn)

        ## calculate the false positive value
        fp = np.sum(np.logical_and(y_pred!=y_true, y_true==0)).astype(int)
        # print(fp)

        ## calculate the false negative value
        fn = np.sum(np.logical_and(y_pred!=y_true, y_true==1)).astype(int)
        # print(fn)

        ## calculate the Accuracy
        acc = ((tp+tn) / y_true.shape[0])*100
        
        if tp==0 : 
            prec = 0
            rec = 0
            f1_score = 0
        else: 
            ## calculate the Precision
            prec = (tp/ (tp+fp))*100

            ## calculate the Recall
            rec = (tp/ (tp + fn))*100
            
            ## calculate the F1-score
            f1_score = 2*prec*rec/(prec+rec)

        print('Accuracy : {}, Precision : {}, Recall :  {}, F1-Score : {}'.format(acc, prec, rec, f1_score))
        return tp, fp, tn, fn

def plot_roc_curve(y_true, y_prob, labels):
    """
    Plots the ROC curve - Binary Classification
    Parameters
    ----------
    y_true : 1-dimensional numpy array of shape (n_samples,) which contains the true values.

    y_prob : 1-dimensional numpy array of shape (n_samples,) which contains the predicted probability values.

    labels : list of output classes.

    """
    ## to store the values to be plotted 
    y_axis = []
    x_axis = []

    ## thresholds to be used
    thresholds = y_prob[:,1] 
    
    # thresholds = thresholds[::int(thresholds.shape[0]/100)]
    thresholds= thresholds.tolist()
    thresholds = list(set(thresholds))
    thresholds.sort()
    thresholds.insert(0,0)
    thresholds.append(1.1)

    # print("thresholds", thresholds)

    ## Loop over the thresholds 
    for threshold in thresholds:
    # for threshold in thresholds:
        # print(threshold)

        ## Calculate the labels corresponding to the threshold value
        y_pred = (y_prob[:,1] >= threshold).astype('int')

        ## evaluate for the predicted labels 
        tp, fp, tn, fn = eval_model(y_true, y_pred, labels)

        ## calculate the True Positive Rate
        tpr = tp/(tp+fn)
        
        ## calculate the False Positive Rate
        fpr = fp/(fp+tn)

        y_axis.append(tpr)

        x_axis.append(fpr)
    
    # Plot the stored values 
    plt.plot(x_axis, y_axis, color='orange')
    plt.plot([0, 1], [0, 1], color='blue', linestyle='--')
    plt.xlabel("FPR")
    plt.ylabel("TPR")
    plt.show()

def plot_roc_multi_label(y_true, y_prob, labels):
    """
    Plots the ROC curve - Multi-Label Classification
    Parameters
    ----------
    y_true : 1-dimensional numpy array of shape (n_samples,) which contains the true values.

    y_prob : 1-dimensional numpy array of shape (n_samples,) which contains the predicted probability values.

    labels : list of output classes.

    """

    ## Create a separate ROC plot for each label
    for label in labels:

        ## For each label make the problem as one vs rest, i.e. add the probabilities of the all the classes other than the selected class 
        ## this converts it into a binary problem and then use the plot_roc_curve func
        bin_y_true = (y_true == label).astype('int')
        
        ## Select only the probabilities for the particular label
        selected_label_prob = y_prob[:,label]
        selected_label_prob = selected_label_prob.reshape((selected_label_prob.shape[0],1))

        ## for the rest class it would be simply 1 - P(label)
        rest_y_prob = np.ones_like(selected_label_prob) - selected_label_prob

        ## create an array of size ( nb_camples, 2) with two columns signifying 
        ## Probaility of rest and probability of the selected class respectively  
        bin_y_prob = np.concatenate((rest_y_prob, selected_label_prob), axis=1)

        # print(bin_y_prob.shape)

        ## use the plot_roc_curve function written for binary classification case  
        plot_roc_curve(bin_y_true, bin_y_prob, [0,1])
        # break

def model_metric(model, X, y_true, labels):
    """
    Evaluates the model's predictions (Classification) and also plots the ROC curve

    Parameters
    ----------
    model : Model to be evaluated 

    X : Data on which the model would be evaluated 

    y_true : 1-dimensional numpy array of shape (n_samples,) which contains the true values.

    labels : list of output classes.

    Returns 
    -------

    conf_mat : returns the confusion matrix values (tp, fp, tn, fn) for binary case 

    conf_mat : returns the l=class wise precison, recall, f1-score and the micro and macro averages 

    """

    ## Calculate the predictions
    y_pred = model.predict(X)

    ## Evaluate the predictions
    conf_mat = eval_model(y_true, y_pred, labels)

    ## plot the ROC curve 
    y_prob = model.predict_proba(X)
    if len(labels) == 2:
        plot_roc_curve(y_true, y_prob, labels)
    else:
        plot_roc_multi_label(y_true, y_prob, labels)
    return conf_mat

def part_abc(file_name, labels):
    """
    Encapsulates all the parts 

    Parameters
    ----------
    file_name : string - Address of the data file 

    labels : list of output classes.

    Returns 
    -------

    conf_mat : returns the confusion matrix values (tp, fp, tn, fn) for binary case 

    conf_mat : returns the l=class wise precison, recall, f1-score and the micro and macro averages 

    """

    ## read the data 
    X, Y = read_data(file_name)

    ## convert the one-hot encoded ouputs to labels 
    enc_Y = np.where(Y==1)[1]
    enc_y = enc_Y.reshape((enc_Y.shape[0], 1))

    ## Shuffle the dataset 
    X, y = shuffle(X, enc_Y, random_state=0)

    ## Split the dataset 
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)

    ## use k-fold cross validation to evaluate Gaussion Naive Bayes model 
    k_fold_cross_validation(GaussianNB, X_train,y_train,4)

    ## dictionary to store the ifferent values of the parameter 
    parameter = {"max_depth": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}

    ## create an instance of the GridSearch with the model type and parameter values 
    GS = GridSearch(DecisionTreeClassifier, parameter)

    ## train and evaluate for the different parameter values
    GS.fit(X_train, y_train, k=4)

    GS.save_best_model("../Weights/DT_best_model.sav")

    GS.load_saved_model("../Weights/DT_best_model.sav")

    ## plot the obtained accuracies for different parameter values
    GS.plot_acc_vs_param()

    ## make prediction from the best model
    y_pred = GS.best_model.predict(X_test)

    ## Evaluate the best model 
    conf_mat = model_metric(GS.best_model, X_test, y_test, labels)
    return conf_mat

print(part_abc("part_A_train.h5", list(range(10))))

print(part_abc("part_B_train.h5", list(range(2))))

